---
title: "Assignment 2"
output: html_notebook
---

1. (1pt) Download the dataset and store it in a dataframe in R. The dataset does not have header, you should
add the headers manually to your dataframe based on the list of attributes provided in
https://archive.ics.uci.edu/ml/datasets/Adult. Also please note that some entries have extra white space. So
to read the data properly, use the option strip.white=TRUE in read.csv function.

```{r}
adult_df = read.csv("adult.data",header = FALSE,strip.white = TRUE, stringsAsFactors = TRUE,col.names = c("age","workclass","fnlwgt","education","education-num","marital-status","occupation",
                                                                                "relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income"))
```
2. (1pt) Explore the overall structure of the dataset using the str() function. Get a summary statistics of each
variable. How many categorical and numeric variables you have in your data? Is there any missing values?

```{r}
str(adult_df)
```

There are nine categorical variables and six numeric variables in the data set. 

```{r}
summary(adult_df$age)
summary(adult_df$workclass)
summary(adult_df$fnlwgt)
summary(adult_df$education)
summary(adult_df$education.num)
summary(adult_df$marital.status)
summary(adult_df$occupation)
summary(adult_df$relationship)
summary(adult_df$race)
summary(adult_df$sex)
summary(adult_df$capital.gain)
summary(adult_df$capital.loss)
summary(adult_df$hours.per.week)
summary(adult_df$native.country)
summary(adult_df$income)
```

There are 1835 "?" values in the occupation column therefore the data set is missing values

3. (1pt) Get the frequency table of the “income” variable to see how many observations you have in each category of the income variable. Is the data balanced? Do we have equal number of samples in each class of income?
```{r}
inc_table = table(adult_df$income)
inc_table
round(prop.table(inc_table) * 100, digits = 2)
```
The data is skewed heavily to the <=50k with that class making up 76% of all entries

4. (3 pts) Explore the data in order to investigate the association between income and the other features. Which of the other features seem most likely to be useful in predicting income.

4a. To explore the relationship between numerical features and “income” variable, you can use side by side box plot and t.test
```{r}
attach(adult_df)
```
```{r}
boxplot(age~income)
boxplot(fnlwgt~income)
boxplot(education.num~income)
boxplot(education.num~income)
boxplot(capital.gain~income)
boxplot(capital.loss~income)
boxplot(hours.per.week~income)
```
```{r}
t.test(age~income)
t.test(fnlwgt~income)
t.test(education.num~income)
t.test(capital.gain~income)
t.test(capital.loss~income)
t.test(hours.per.week~income)
```

For the numerical features it would appear that there is a relationship between income and the following: age, education-num, capitol-gain, capitol-loss, and hours-per-week
```{r}
adult_df_old = adult_df
adult_df = adult_df[-3]
```


4b. To explore the relationship between categorical features and “income” variable, you can use frequency table and chisquare test (note that chisquare test might throw a warning if there are cells whose expected counts in the frequency table is less 5. This warning means the p-values reported from chisquare test may be incorrect due to low counts and are not reliable. You can ignore the warning for this assignment).

```{r}
workclass_tbl = table(workclass, income)
workclass_tbl
chisq.test(workclass_tbl)

marital.status_tbl = table(marital.status, income)
marital.status_tbl
chisq.test(marital.status_tbl)

education_tbl = table(education, income)
education_tbl
chisq.test(education_tbl)

occupation_tbl = table(occupation, income)
occupation_tbl
chisq.test(occupation_tbl)

relationship_tbl = table(relationship, income)
relationship_tbl
chisq.test(relationship_tbl)

sex_tbl = table(sex, income)
sex_tbl
chisq.test(sex_tbl)

native.country_tbl = table(native.country, income)
native.country_tbl
chisq.test(native.country_tbl[-1]) #to remove "?" from the factor since it breaks the chi-squared test
```

4c.  Based on your data exploration above, decide which attributes you are going to use to predict income.
Explain your reason for selecting these attributes.

I'm using the following attributes because I have shown that there is a statistically significant relationship between them and income: relationship, workclass, marital-status, education, occupation, sex, native-country, age, education-num, capitol-gain, capitol-loss, and hours-per-week

5. (1 pt) An initial data exploration shows that the missing values in the dataset are denoted by “?” not
NA. Change all the “?” characters in the dataframe to NA

```{r}
adult_df[adult_df == "?"] <- NA
```

6. (1pt) Use the command colSums(is.na(<your dataframe>) to get the number of missing values in each
column of your dataframe. Which columns have missing values?

```{r}
colSums(is.na(adult_df))
```
workclass, occupation and native.country have missing values

7. (3 pt) There are several ways we can deal with missing values. The easiest approach is to remove all the
rows with missing values. However, if a large number of rows have missing values removing them will
result in loss of information and may affect the classifier performance. If a large number of rows have
missing values, then it is typically better to replace missing data with some values. This is called data
imputation. Several methods for missing data imputation exist. The most naïve method (which we will use
here) is to replace the missing values with mean of the column (for a numerical column) or mode/majority
value of the column (for a categorical column). We will use a more advanced data imputation method in a
later module. For now, replace the missing values in a numerical column with the mean of the column and
the missing values in a categorical column with the mode/majority of the column. After imputation, use
colSums(is.na(<your dataframe>) to make sure that your dataframe no longer has missing values

```{r}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```
```{r}
adult_df$workclass[is.na(adult_df$workclass)] = Mode(adult_df$workclass)
adult_df$occupation[is.na(adult_df$occupation)] = Mode(adult_df$occupation)
adult_df$native.country[is.na(adult_df$native.country)] = Mode(adult_df$native.country)
```
```{r}
colSums(is.na(adult_df))
```

8. (2 pt) This dataset has several categorical variables. With the exception of few models ( such as Naiive Bayes and tree-based models) most machine learning models require numeric features and cannot work directly with categorical data. One way to deal with categorical variables is to assign numeric indices to each level. However, this imposes an artificial ordering on an unordered categorical variable. For example, suppose that we have a categorical variable primary color with three levels: “red”,”blue”,”green”. If we convert “red” to 0 , “blue” to 1 and “green” to 2 then we are telling our model that red < blue< green which is not correct. A better way to encode an unordered categorical variable is to do one-hot-encoding. In one hot-encoding we create a dummy binary variable for each level of a categorical variable. For example we can represent the primary color variable by three binary dummy variables, one for each color (red, blue, and green) . If the color is red, then the variable red takes value 1 while blue and green both take the value zero.

Do one-hot-encoding of all your unordered categorical variables (except the income variable). You can use the function one_hot from mltools package to one-hot encode all categorical variables in a dataset. Please refer to https://rdrr.io/cran/mltools/man/one_hot.html . Use option DropUnusedLevels=True to avoid creating a binary variable for unused levels of a factor variable.

Please note that the one_hot function takes a data table not a dataframe. You can convert a dataframe to datatable by using as.data.table method https://www.rdocumentation.org/packages/data.table/versions/1.12.8/topics/as.data.table. Make sure to use library(data.table) before using as.data.table method. You can covert a datatable back to a dataframe by using as.data.frame method https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/as.data.frame

```{r}
#install.packages("mltools")
library(mltools)
library(data.table)
```

```{r}
encoded_table = one_hot(data.table(adult_df[,-which(names(adult_df) == "income")]), dropUnusedLevels = TRUE)
encoded_df = as.data.frame(encoded_table)
encoded_df$income = adult_df$income
names(encoded_df)
```

9. Set the seed of the random number generator to a fixed integer, say 1, so that I can reproduce your work:
```{r}
set.seed(1)
```


10. (1 pt) Scale all numeric features using Min-Max scaling

```{r}
normalize = function(col){
    (col - min(col))/(max(col) - min(col))
}
normalized_df = as.data.frame(sapply(encoded_df[-(length(encoded_df))], normalize))
```

11. (1pt) Randomize the order of the rows in the dataset.

```{r}
encoded_df = encoded_df[sample(nrow(encoded_df),replace = FALSE),]
normalized_df = as.data.frame(sapply(encoded_df[-(length(encoded_df))], normalize))
```

12. (4 pts) Use 5-fold cross validation with KNN to predict the “income” variable and report the cross-
validation error. ( You can find an example in slides 51-53 of module 4 lecture notes).

```{r}
library(lattice)
library(ggplot2)
library(caret)
library(class)
```

```{r}
knn_fold=function(features,target,fold,k){
  train=features[-fold,]
  validation=features[fold,]
  train_labels=target[-fold]
  validation_labels=target[fold]
  validation_preds=knn(train,validation,train_labels,k=k)
  t= table(validation_labels,validation_preds)
  error=(t[1,2]+t[2,1])/(t[1,1]+t[1,2]+t[2,1]+t[2,2])
  return(error)
}

crossValidationError=function(features,target,k,k_cross){
  folds=createFolds(target,k=k_cross)
  errors=sapply(folds,knn_fold,features=features, target=target,k=k)
}
```

```{r}
k = floor(sqrt(nrow(normalized_df)*0.8))
```

```{r}
cf_error = crossValidationError(normalized_df,encoded_df$income, k = k, k_cross=5)
```

```{r}
mean(cf_error)
```




















